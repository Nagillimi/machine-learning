{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging/Model Diagnostics?\n",
    "\n",
    "If a model makes unacceptable large errors in predictions:\n",
    "\n",
    "- get more training examples\n",
    "- try smaller sets of features\n",
    "- try getting additional features\n",
    "- try adding polynomial features ($x_1^2,x_2^2,x_1,x_2,etc.$)\n",
    "- try increasing $\\lambda$\n",
    "- try decreasing $\\lambda$\n",
    "\n",
    "Key to being effective is choosing where to put your *time*. To gain more insight into this, run some diagnositcs to diagnose to prove a symptom.\n",
    "\n",
    "Diagnostics can take time implement however, but it's often worth it in the long run since model prediction can be a black box.\n",
    "\n",
    "## Evaluating Your Model (Regression)\n",
    "\n",
    "1. get a training set\n",
    "2. break it into 70$ that you'll use, 30% that you'll save as a test set (80/20 works too)\n",
    "3. train the model on the training set and test the output on the test set!\n",
    "\n",
    "Fitting parameters by minimizing the cost function:\n",
    "\n",
    "$J(\\vec{w}, b) = [\\frac{1}{2m_{train}} \\sum\\limits_{i=1}^{m_{train}}(f_{\\vec{w}, b}(\\vec{x}^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m_{train}} \\sum\\limits_{i=1}^{n}w_j^2]$\n",
    "\n",
    "Compute the test & training set errors:\n",
    "\n",
    "$J_{test}(\\vec{w}, b) = \\frac{1}{2m_{test}} [\\sum\\limits_{i=1}^{m_{test}}(f_{\\vec{w}, b}(\\vec{x}^{(i)}_{test}) - y^{(i)}_{test})^2]$\n",
    "\n",
    "$J_{train}(\\vec{w}, b) = \\frac{1}{2m_{train}} [\\sum\\limits_{i=1}^{m_{train}}(f_{\\vec{w}, b}(\\vec{x}^{(i)}_{train}) - y^{(i)}_{train})^2]$\n",
    "\n",
    "(Does include the regularization term)\n",
    "\n",
    "This provides an insight on how well your model is generalizing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Your Model (Calssification)\n",
    "\n",
    "Scaling to classification, update the loss function! First fit the parameters by minimizing the cost function:\n",
    "\n",
    "$J(\\vec{w}, b) = -\\frac{1}{2m_{train}}\\sum\\limits_{i=1}^{m_{train}}[y^{(i)}log(f_{\\vec{w}, b}(\\vec{x}^{(i)})) + (1 - y^{(i)})log(1 - f_{\\vec{w}, b}(\\vec{x}^{(i)}))] + \\frac{1}{2m_{train}}\\sum\\limits_{i=1}^{n}w_j^2$\n",
    "\n",
    "Compute the test & training set errors:\n",
    "\n",
    "$J_{test}(\\vec{w}, b) = -\\frac{1}{2m_{test}}\\sum\\limits_{i=1}^{m_{test}}[y^{(i)}_{test}log(f_{\\vec{w}, b}(\\vec{x}^{(i)}_{test})) + (1 - y^{(i)}_{test})log(1 - f_{\\vec{w}, b}(\\vec{x}^{(i)}_{test}))]$\n",
    "\n",
    "$J_{train}(\\vec{w}, b) = -\\frac{1}{2m_{train}}\\sum\\limits_{i=1}^{m_{train}}[y^{(i)}_{train}log(f_{\\vec{w}, b}(\\vec{x}^{(i)}_{train})) + (1 - y^{(i)}_{train})log(1 - f_{\\vec{w}, b}(\\vec{x}^{(i)}_{train}))]$\n",
    "\n",
    "This will work well for identifying errors.\n",
    "\n",
    "To discover which fraction of the test set the model failed predicting for, simply apply a threshold on $f_{\\vec{w}, b}(\\vec{x}^{(i)})$ and assign yes/no.\n",
    "\n",
    "$\n",
    "\\^{y} = \\begin{cases}\n",
    "1 \\text{ if } f_{\\vec{w}, b}(\\vec{x}^{(i)}) \\ge 0.5\\\\\n",
    "0 \\text{ if } f_{\\vec{w}, b}(\\vec{x}^{(i)}) < 0.5\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "count $\\^{y} \\ne y$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
