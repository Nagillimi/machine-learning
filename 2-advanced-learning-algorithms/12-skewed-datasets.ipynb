{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skewed Datasets\n",
    "\n",
    "It may not be the best idea to select a model with the lowest classification error, since it can lead to missed diagnoses, for ex. This leads to measurements on false negative and positives.\n",
    "\n",
    "## Terminology\n",
    "\n",
    "You always want high precision & recall!\n",
    "\n",
    "$Precision = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}} = \\frac{\\text{True Positives}}{\\text{Total Predicted Positives}}$\n",
    "\n",
    "$Recall = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}} = \\frac{\\text{True Positives}}{\\text{Total Actual Positives}}$\n",
    "\n",
    "Although, there's often a tradeoff between precision & recall. Therefore, the application of the model will inform which camp to put confidence towards.\n",
    "\n",
    "![ ](precision-recall.png)\n",
    "\n",
    "Can also use the F1 score which combines both precision and recall into a single score (harmonic mean, emphasizes the smaller params more).\n",
    "\n",
    "$F_1 score = \\frac{1}{\\frac{1}{2}(\\frac{1}{P} + \\frac{1}{R})} = 2 \\frac{PR}{P + R}$\n",
    "\n",
    "Take the highest $F_1score$ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
