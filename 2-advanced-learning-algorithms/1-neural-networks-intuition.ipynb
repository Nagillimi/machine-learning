{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Course Outine\n",
    "> \n",
    "> Neural networks\n",
    "> \n",
    "> - inference (prediction)\n",
    "> - training\n",
    "> \n",
    "> Practical advice for building ML systems \n",
    "> Decision trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurons and the Brain\n",
    "\n",
    "Deep Learning = Neural Networks, just reanmed for marketting lol.\n",
    "\n",
    "Big examples:\n",
    "\n",
    "- climate change\n",
    "- mediucal imaging\n",
    "- speech to text\n",
    "\n",
    "## Comparing to Anatomy\n",
    "\n",
    "The mathematical model represents a very simple anatomical simulation of a neuron. One big caveat is that we actually don't understand how the brain actually works, so it won't help us identify the foundation of true intelligence. This is really the end of biological inspiration.\n",
    "\n",
    "![ ](compare-to-anatomy.png)\n",
    "\n",
    "Historically, regression and classification has a low ceiling of performance wrt to the amount of data collected. Meaning, if more and more data was collected, the performance of these algorithms don't really improve. Neural networks on the other hand continue to improve with more and more data!\n",
    "\n",
    "### Example - Demand Prediction\n",
    "\n",
    "Goal to create a model to represent the demand for a new brand of T-shirt. Listing the features for trianing,\n",
    "\n",
    "- price\n",
    "- shipping costs\n",
    "- marketting\n",
    "- material\n",
    "\n",
    "Regression would have taken these features and created a single probability function based on multiple weight parameters and a single bias parameter. Instead, creating a neural network involves taking these features and creating multiple combinations of probability functions all incorporated towards the same main demand prediction goal as regression, individually called \"activation\" (biologically inspired from the neuron). Listing these artificial neurons with their respective components,\n",
    "\n",
    "- affordability = f(price, shipping costs)\n",
    "- awareness = f(marketting)\n",
    "- perceived quality = f(price, material)\n",
    "\n",
    "With finally:\n",
    "\n",
    "- Probability of being a top seller = f(affordability, awareness, perceived quality)\n",
    "\n",
    "Each of these probability functions (as well as the input) are called \"layers\", which each have their respective activations and are represented individually by a regression model. Listing the numbers involved in this neural network, {4, 3, 1}numbers.\n",
    "\n",
    "> Note:\n",
    ">\n",
    "> In practice, it's extemely tedious to manually identify the components of the input layer that make up the first layer. Therefore, we typically have all the inputs inform a single neuron in the first layer and provide feedback on components that have relevance to the activation.\n",
    "\n",
    "Representing this mathematically,\n",
    "\n",
    "$\\vec{x} = (x, y) -> \\vec{a} -> a$\n",
    "\n",
    "- $\\vec{x}$: input layer\n",
    "- $\\vec{a}$: hidden layer(s)\n",
    "- $a$: output layer\n",
    "\n",
    "The *architecture* of a neural network refers to the decision of the number of hidden layers and the number of components in those layers (how many neurons per layer).\n",
    "\n",
    "### Example - Facial Recognition\n",
    "\n",
    "Input is a picture made up of 1000 pixels. Running the self-training nerual network creates these hidden layers,\n",
    "\n",
    "- recognition of edges from multiple pixels\n",
    "- detecting individual facial components from those edges\n",
    "- building a face based on those individual facial components\n",
    "\n",
    "Which each grow their pixel regions/representations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
