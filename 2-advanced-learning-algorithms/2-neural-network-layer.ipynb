{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Layer\n",
    "\n",
    "Each neuron in a layer is represented as a regression function, which output an activation. Since all inputs are fed into each of these regression functions, the exact same vector representation is used to deal with multiple features but are numbered based on the neuron ID (in the layer).\n",
    "\n",
    "### Example - Neural Network {4, 3, 1}\n",
    "\n",
    "Has \"2 layers\" (we don't coun't the input layer):\n",
    "\n",
    "- layer 0 (input layer) = $\\vec{x}$.\n",
    "- layer 1 is comprised of its own parameters based on logistic regression = $(\\vec{w_i}, b_i)$, where $i$ is the neuron ID in the layer. The output of these individual neurons are: $a = g(\\vec{w_1} \\cdot \\vec{x} + b_1)$\n",
    "- layer 2 is the final activation = $a$.\n",
    "\n",
    "The combined output of $\\vec{a}$ is the vector of all the activations from layer 1. Since neural networks have multiple layers, some better notation,\n",
    "\n",
    "- $\\vec{a}^{[l]}$ = the vector representing the activations of all the neurons in layer $l$.\n",
    "- $\\vec{w_j}^{[l]}$ = the vector of weight parameters used for all the inputs for the $j^{th}$ neuron in layer $l$.\n",
    "\n",
    "Representing the output layer (scalar in this example) based on this notation,\n",
    "\n",
    "$a_1^{[2]} = g(\\vec{w_1}^{[2]} \\cdot \\vec{a}^{[2]} + b_1^{[2]})$\n",
    "\n",
    "And \n",
    "\n",
    "$a^{[2]} = f(a_1^{[2]})$\n",
    "\n",
    "> Note:\n",
    ">\n",
    "> For the demand example, you could apply a threshold on this output value to represent yes or no.\n",
    "\n",
    "### Mathematical Activation for all Neurons\n",
    "\n",
    "$\\vec{a_j}^{[l]} = g(\\vec{w_j}^{[l]} \\cdot \\vec{a}^{[l-1]} + b_j^{[l]})$\n",
    "\n",
    "- $a$: activation\n",
    "- $j$: neuron\n",
    "- $l$: layer\n",
    "\n",
    "The input layer is also denoted by $\\vec{a}^{[0]}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference - Forward Propagation\n",
    "\n",
    "Propagating the activations forward through a network refers to computing the activation vectors from left to right until defining the output; traversing the netork forward."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
